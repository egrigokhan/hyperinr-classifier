{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MNISTSiren+INRwithPretrainedCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ET0ETjlzY6U6",
        "outputId": "befe24a7-5745-4143-9e37-11edfc795ee3"
      },
      "source": [
        "!git clone https://github.com/vsitzmann/siren.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'siren' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjWWAEZLZBDa",
        "outputId": "d671c4ca-4476-40eb-8d9a-254f07f81251"
      },
      "source": [
        "%cd siren"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/siren\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr-TXeyFqSd0"
      },
      "source": [
        "from modules import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwyJWMCtqT_9"
      },
      "source": [
        "class ConvImgEncoder(nn.Module):\n",
        "    def __init__(self, channel, image_resolution):\n",
        "        super().__init__()\n",
        "\n",
        "        # conv_theta is input convolution\n",
        "        self.conv_theta = nn.Conv2d(channel, 128, 3, 1, 1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            Conv2dResBlock(256, 256),\n",
        "            Conv2dResBlock(256, 256),\n",
        "            Conv2dResBlock(256, 256),\n",
        "            Conv2dResBlock(256, 256),\n",
        "            nn.Conv2d(256, 256, 1, 1, 0)\n",
        "        )\n",
        "\n",
        "        self.relu_2 = nn.ReLU(inplace=True)\n",
        "        self.fc = nn.Linear(784, 1)\n",
        "\n",
        "        self.image_resolution = image_resolution\n",
        "\n",
        "    def forward(self, I):\n",
        "        o = self.relu(self.conv_theta(I))\n",
        "        o = self.cnn(o)\n",
        "\n",
        "        o = self.fc(self.relu_2(o).view(o.shape[0], 256, -1)).squeeze(-1)\n",
        "        return o"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB1Nvi4ZqU_U"
      },
      "source": [
        "net_ = ConvImgEncoder(1, 28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bEldZ80qeT3",
        "outputId": "77d3bb43-cde6-4d54-802f-4a158cbb248f"
      },
      "source": [
        "net_(torch.ones((1, 1, 28, 28))).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWHBcZ5xZeaJ"
      },
      "source": [
        "'''Modules for hypernetwork experiments, Paper Sec. 4.4\n",
        "'''\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from collections import OrderedDict\n",
        "import modules\n",
        "\n",
        "\n",
        "class HyperNetwork(nn.Module):\n",
        "    def __init__(self, hyper_in_features, hyper_hidden_layers, hyper_hidden_features, hypo_module):\n",
        "        '''\n",
        "\n",
        "        Args:\n",
        "            hyper_in_features: In features of hypernetwork\n",
        "            hyper_hidden_layers: Number of hidden layers in hypernetwork\n",
        "            hyper_hidden_features: Number of hidden units in hypernetwork\n",
        "            hypo_module: MetaModule. The module whose parameters are predicted.\n",
        "        '''\n",
        "        super().__init__()\n",
        "\n",
        "        hypo_parameters = hypo_module.meta_named_parameters()\n",
        "\n",
        "        self.names = []\n",
        "        self.nets = nn.ModuleList()\n",
        "        self.param_shapes = []\n",
        "        for name, param in hypo_parameters:\n",
        "            self.names.append(name)\n",
        "            self.param_shapes.append(param.size())\n",
        "\n",
        "            hn = modules.FCBlock(in_features=hyper_in_features, out_features=int(torch.prod(torch.tensor(param.size()))),\n",
        "                                 num_hidden_layers=hyper_hidden_layers, hidden_features=hyper_hidden_features,\n",
        "                                 outermost_linear=True, nonlinearity='relu')\n",
        "            self.nets.append(hn)\n",
        "\n",
        "            if 'weight' in name:\n",
        "                self.nets[-1].net[-1].apply(lambda m: hyper_weight_init(m, param.size()[-1]))\n",
        "            elif 'bias' in name:\n",
        "                self.nets[-1].net[-1].apply(lambda m: hyper_bias_init(m))\n",
        "\n",
        "    def forward(self, z):\n",
        "        '''\n",
        "        Args:\n",
        "            z: Embedding. Input to hypernetwork. Could be output of \"Autodecoder\" (see above)\n",
        "\n",
        "        Returns:\n",
        "            params: OrderedDict. Can be directly passed as the \"params\" parameter of a MetaModule.\n",
        "        '''\n",
        "        params = OrderedDict()\n",
        "        for name, net, param_shape in zip(self.names, self.nets, self.param_shapes):\n",
        "            batch_param_shape = (-1,) + param_shape\n",
        "            params[name] = net(z).reshape(batch_param_shape)\n",
        "        return params\n",
        "\n",
        "\n",
        "class NeuralProcessImplicit2DHypernet(nn.Module):\n",
        "    '''A canonical 2D representation hypernetwork mapping 2D coords to out_features.'''\n",
        "    def __init__(self, in_features, out_features, image_resolution=None, encoder_nl='sine'):\n",
        "        super().__init__()\n",
        "\n",
        "        latent_dim = 256\n",
        "        self.hypo_net = modules.SingleBVPNet(out_features=out_features, type='sine', sidelength=image_resolution,\n",
        "                                             in_features=2)\n",
        "        self.hyper_net = HyperNetwork(hyper_in_features=latent_dim, hyper_hidden_layers=3, hyper_hidden_features=256,\n",
        "                                      hypo_module=self.hypo_net)\n",
        "        self.set_encoder = modules.SetEncoder(in_features=in_features, out_features=latent_dim, num_hidden_layers=2,\n",
        "                                              hidden_features=latent_dim, nonlinearity=encoder_nl)\n",
        "        print(self)\n",
        "\n",
        "    def freeze_hypernet(self):\n",
        "        for param in self.hyper_net.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def get_hypo_net_weights(self, model_input):\n",
        "        pixels, coords = model_input['img_sub'], model_input['coords_sub']\n",
        "        ctxt_mask = model_input.get('ctxt_mask', None)\n",
        "        embedding = self.set_encoder(coords, pixels, ctxt_mask=ctxt_mask)\n",
        "        hypo_params = self.hyper_net(embedding)\n",
        "        return hypo_params, embedding\n",
        "\n",
        "    def forward(self, model_input):\n",
        "        if model_input.get('embedding', None) is None:\n",
        "            pixels, coords = model_input['img_sub'], model_input['coords_sub']\n",
        "            ctxt_mask = model_input.get('ctxt_mask', None)\n",
        "            embedding = self.set_encoder(coords, pixels, ctxt_mask=ctxt_mask)\n",
        "        else:\n",
        "            embedding = model_input['embedding']\n",
        "        hypo_params = self.hyper_net(embedding)\n",
        "\n",
        "        model_output = self.hypo_net(model_input, params=hypo_params)\n",
        "        return {'model_in':model_output['model_in'], 'model_out':model_output['model_out'], 'latent_vec':embedding,\n",
        "                'hypo_params':hypo_params}\n",
        "\n",
        "\n",
        "class ConvolutionalNeuralProcessImplicit2DHypernet(nn.Module):\n",
        "    def __init__(self, in_features, out_features, image_resolution=28, latent_dim=784, partial_conv=False):\n",
        "        super().__init__()\n",
        "\n",
        "        if partial_conv:\n",
        "            self.encoder = modules.PartialConvImgEncoder(channel=in_features, image_resolution=image_resolution)\n",
        "        else:\n",
        "            self.encoder = ConvImgEncoder(channel=in_features, image_resolution=image_resolution)\n",
        "        self.hypo_net = modules.FCBlock(2, 1, 3, 256, outermost_linear=True, nonlinearity='sine', weight_init=None)\n",
        "        self.hyper_net = HyperNetwork(hyper_in_features=latent_dim, hyper_hidden_layers=1, hyper_hidden_features=256,\n",
        "                                      hypo_module=self.hypo_net)\n",
        "\n",
        "    def forward(self, model_input):\n",
        "        if model_input.get('embedding', None) is None:\n",
        "            embedding = self.encoder(model_input['img_sparse'])\n",
        "        else:\n",
        "            embedding = model_input['embedding']\n",
        "        hypo_params = self.hyper_net(embedding)\n",
        "\n",
        "        model_output = self.hypo_net(model_input[\"coords\"], params=hypo_params)\n",
        "\n",
        "        return {'model_out': model_output, 'latent_vec': embedding,\n",
        "                'hypo_params': hypo_params}\n",
        "\n",
        "    def get_hypo_net_weights(self, model_input):\n",
        "        embedding = self.encoder(model_input['img_sparse'])\n",
        "        hypo_params = self.hyper_net(embedding)\n",
        "        return hypo_params, embedding\n",
        "\n",
        "    def freeze_hypernet(self):\n",
        "        for param in self.hyper_net.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in self.encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "\n",
        "############################\n",
        "# Initialization schemes\n",
        "def hyper_weight_init(m, in_features_main_net):\n",
        "    if hasattr(m, 'weight'):\n",
        "        nn.init.kaiming_normal_(m.weight, a=0.0, nonlinearity='relu', mode='fan_in')\n",
        "        m.weight.data = m.weight.data / 1.e2\n",
        "\n",
        "    if hasattr(m, 'bias'):\n",
        "        with torch.no_grad():\n",
        "            m.bias.uniform_(-1/in_features_main_net, 1/in_features_main_net)\n",
        "\n",
        "\n",
        "def hyper_bias_init(m):\n",
        "    if hasattr(m, 'weight'):\n",
        "        nn.init.kaiming_normal_(m.weight, a=0.0, nonlinearity='relu', mode='fan_in')\n",
        "        m.weight.data = m.weight.data / 1.e2\n",
        "\n",
        "    if hasattr(m, 'bias'):\n",
        "        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n",
        "        with torch.no_grad():\n",
        "            m.bias.uniform_(-1/fan_in, 1/fan_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDf-ZNg_ZjE4"
      },
      "source": [
        "import torchvision.datasets as datasets\n",
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
        "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tFLivPbaWHc"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=8, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6IzSxgXavVg",
        "outputId": "00d450d3-ea42-4a61-fefa-8114e15df19a"
      },
      "source": [
        "print(mnist_trainset[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PIL.Image.Image image mode=L size=28x28 at 0x7F942AB6CBD0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDJ0X5yIdm2K"
      },
      "source": [
        "def get_mgrid(sidelen, dim=2):\n",
        "    '''Generates a flattened grid of (x,y,...) coordinates in a range of -1 to 1.\n",
        "    sidelen: int\n",
        "    dim: int'''\n",
        "    tensors = tuple(dim * [torch.linspace(-1, 1, steps=sidelen)])\n",
        "    mgrid = torch.stack(torch.meshgrid(*tensors), dim=-1)\n",
        "    mgrid = mgrid.reshape(-1, dim)\n",
        "    return mgrid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TeeO7o5eb73"
      },
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class ImageFitting(Dataset):\n",
        "    def __init__(self, sidelength, img):\n",
        "        super().__init__()\n",
        "        print(img.shape)\n",
        "        self.pixels = img.view(-1, 1)\n",
        "        self.coords = get_mgrid(sidelength, 2)\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1\n",
        "\n",
        "    def __getitem__(self, idx):    \n",
        "        if idx > 0: raise IndexError\n",
        "            \n",
        "        return self.coords, self.pixels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBQZwwoJeZBt",
        "outputId": "de6bd5c4-0a97-48dd-d5d1-77dad91a7e9f"
      },
      "source": [
        "import numpy as np\n",
        "cameraman = ImageFitting(28, torch.Tensor(np.array(mnist_trainset[0][0])))\n",
        "dataloader = DataLoader(cameraman, batch_size=1, pin_memory=True, num_workers=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxlS9JpJhtLm",
        "outputId": "476f9a3f-8e66-435c-cc24-6fbba176a25a"
      },
      "source": [
        "img_siren = modules.FCBlock(2, 1, 3, 128, outermost_linear=True, nonlinearity='sine', weight_init=None)\n",
        "img_siren.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FCBlock(\n",
              "  (net): MetaSequential(\n",
              "    (0): MetaSequential(\n",
              "      (0): BatchLinear(in_features=2, out_features=128, bias=True)\n",
              "      (1): Sine()\n",
              "    )\n",
              "    (1): MetaSequential(\n",
              "      (0): BatchLinear(in_features=128, out_features=128, bias=True)\n",
              "      (1): Sine()\n",
              "    )\n",
              "    (2): MetaSequential(\n",
              "      (0): BatchLinear(in_features=128, out_features=128, bias=True)\n",
              "      (1): Sine()\n",
              "    )\n",
              "    (3): MetaSequential(\n",
              "      (0): BatchLinear(in_features=128, out_features=128, bias=True)\n",
              "      (1): Sine()\n",
              "    )\n",
              "    (4): MetaSequential(\n",
              "      (0): BatchLinear(in_features=128, out_features=1, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lnXAIpFFdVC"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "CNT_kaQqeVA-",
        "outputId": "f6b86eca-3e93-476b-fc1b-a7b7fb44d0c4"
      },
      "source": [
        "total_steps = 1000000 # Since the whole image is our dataset, this just means 500 gradient descent steps.\n",
        "steps_til_summary = 50\n",
        "\n",
        "optim = torch.optim.Adam(lr=1e-6, params=net.hyper_net.parameters())\n",
        "\n",
        "model_input, ground_truth = get_mgrid(28, 2), torch.Tensor(np.array(mnist_trainset[step % len(mnist_trainset)][0])).reshape((784, 1))\n",
        "model_input, ground_truth = model_input.cuda(), ground_truth.cuda()\n",
        "\n",
        "for step in range(total_steps):\n",
        "    \n",
        "    out = net({'embedding': ground_truth.view((1, 784)).cuda(), 'coords': model_input.cuda()})\n",
        "    model_output = nn.Sigmoid()(out[\"model_out\"])\n",
        "    hypo_params = out[\"hypo_params\"]\n",
        "    all_hypo_params = torch.cat([x.view(-1) for x in list(hypo_params.values())])\n",
        "    # model_output, coords = img_siren(model_input)    \n",
        "    loss = ((model_output.cuda() - (ground_truth / 255))**2).mean() + 1000 * ((all_hypo_params.cuda())**2).mean()\n",
        "    \n",
        "    if not step % 250:\n",
        "        print(\"Step %d, Total loss %0.6f\" % (step, loss))\n",
        "\n",
        "        print(torch.max(model_output))\n",
        "        print(torch.max(ground_truth))\n",
        "\n",
        "        fig, axes = plt.subplots(1,3, figsize=(18,6))\n",
        "        axes[0].imshow(model_output.cpu().view(28,28).detach().numpy())\n",
        "        axes[1].imshow((ground_truth / 255).cpu().view(28,28).detach().numpy())\n",
        "        plt.show()\n",
        "\n",
        "    optim.zero_grad()\n",
        "    loss.backward()\n",
        "    optim.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-6142fdb860f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msteps_til_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0moptim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyper_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_trainset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_trainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tLtEcPNhz4O"
      },
      "source": [
        "class SineLayer(nn.Module):\n",
        "    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n",
        "    \n",
        "    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the \n",
        "    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a \n",
        "    # hyperparameter.\n",
        "    \n",
        "    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of \n",
        "    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n",
        "    \n",
        "    def __init__(self, in_features, out_features, bias=True,\n",
        "                 is_first=False, omega_0=30):\n",
        "        super().__init__()\n",
        "        self.omega_0 = omega_0\n",
        "        self.is_first = is_first\n",
        "        \n",
        "        self.in_features = in_features\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
        "        \n",
        "        self.init_weights()\n",
        "    \n",
        "    def init_weights(self):\n",
        "        with torch.no_grad():\n",
        "            if self.is_first:\n",
        "                self.linear.weight.uniform_(-1 / self.in_features, \n",
        "                                             1 / self.in_features)      \n",
        "            else:\n",
        "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n",
        "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
        "        \n",
        "    def forward(self, input):\n",
        "        return torch.sin(self.omega_0 * self.linear(input))\n",
        "    \n",
        "    def forward_with_intermediate(self, input): \n",
        "        # For visualization of activation distributions\n",
        "        intermediate = self.omega_0 * self.linear(input)\n",
        "        return torch.sin(intermediate), intermediate\n",
        "    \n",
        "    \n",
        "class Siren(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, outermost_linear=False, \n",
        "                 first_omega_0=30, hidden_omega_0=30.):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.net = []\n",
        "        self.net.append(SineLayer(in_features, hidden_features, \n",
        "                                  is_first=True, omega_0=first_omega_0))\n",
        "\n",
        "        for i in range(hidden_layers):\n",
        "            self.net.append(SineLayer(hidden_features, hidden_features, \n",
        "                                      is_first=False, omega_0=hidden_omega_0))\n",
        "\n",
        "        if outermost_linear:\n",
        "            final_linear = nn.Linear(hidden_features, out_features)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                final_linear.weight.uniform_(-np.sqrt(6 / hidden_features) / hidden_omega_0, \n",
        "                                              np.sqrt(6 / hidden_features) / hidden_omega_0)\n",
        "                \n",
        "            self.net.append(final_linear)\n",
        "        else:\n",
        "            self.net.append(SineLayer(hidden_features, out_features, \n",
        "                                      is_first=False, omega_0=hidden_omega_0))\n",
        "        \n",
        "        self.net = nn.Sequential(*self.net)\n",
        "    \n",
        "    def forward(self, coords):\n",
        "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
        "        output = self.net(coords)\n",
        "        return output, coords        \n",
        "\n",
        "    def forward_with_activations(self, coords, retain_grad=False):\n",
        "        '''Returns not only model output, but also intermediate activations.\n",
        "        Only used for visualizing activations later!'''\n",
        "        activations = OrderedDict()\n",
        "\n",
        "        activation_count = 0\n",
        "        x = coords.clone().detach().requires_grad_(True)\n",
        "        activations['input'] = x\n",
        "        for i, layer in enumerate(self.net):\n",
        "            if isinstance(layer, SineLayer):\n",
        "                x, intermed = layer.forward_with_intermediate(x)\n",
        "                \n",
        "                if retain_grad:\n",
        "                    x.retain_grad()\n",
        "                    intermed.retain_grad()\n",
        "                    \n",
        "                activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = intermed\n",
        "                activation_count += 1\n",
        "            else: \n",
        "                x = layer(x)\n",
        "                \n",
        "                if retain_grad:\n",
        "                    x.retain_grad()\n",
        "                    \n",
        "            activations['_'.join((str(layer.__class__), \"%d\" % activation_count))] = x\n",
        "            activation_count += 1\n",
        "\n",
        "        return activations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaGVJZGojWTC",
        "outputId": "5b89d1aa-1e9f-4afd-de36-ecebb4eb29b7"
      },
      "source": [
        "net = ConvolutionalNeuralProcessImplicit2DHypernet(1, 1, image_resolution=28)\n",
        "net.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvolutionalNeuralProcessImplicit2DHypernet(\n",
              "  (encoder): ConvImgEncoder(\n",
              "    (conv_theta): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (cnn): Sequential(\n",
              "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2dResBlock(\n",
              "        (convs): Sequential(\n",
              "          (0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          (1): ReLU()\n",
              "          (2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          (3): ReLU()\n",
              "        )\n",
              "        (final_relu): ReLU()\n",
              "      )\n",
              "      (3): Conv2dResBlock(\n",
              "        (convs): Sequential(\n",
              "          (0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          (1): ReLU()\n",
              "          (2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          (3): ReLU()\n",
              "        )\n",
              "        (final_relu): ReLU()\n",
              "      )\n",
              "      (4): Conv2dResBlock(\n",
              "        (convs): Sequential(\n",
              "          (0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          (1): ReLU()\n",
              "          (2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          (3): ReLU()\n",
              "        )\n",
              "        (final_relu): ReLU()\n",
              "      )\n",
              "      (5): Conv2dResBlock(\n",
              "        (convs): Sequential(\n",
              "          (0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          (1): ReLU()\n",
              "          (2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          (3): ReLU()\n",
              "        )\n",
              "        (final_relu): ReLU()\n",
              "      )\n",
              "      (6): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (relu_2): ReLU(inplace=True)\n",
              "    (fc): Linear(in_features=784, out_features=1, bias=True)\n",
              "  )\n",
              "  (hypo_net): FCBlock(\n",
              "    (net): MetaSequential(\n",
              "      (0): MetaSequential(\n",
              "        (0): BatchLinear(in_features=2, out_features=256, bias=True)\n",
              "        (1): Sine()\n",
              "      )\n",
              "      (1): MetaSequential(\n",
              "        (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "        (1): Sine()\n",
              "      )\n",
              "      (2): MetaSequential(\n",
              "        (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "        (1): Sine()\n",
              "      )\n",
              "      (3): MetaSequential(\n",
              "        (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "        (1): Sine()\n",
              "      )\n",
              "      (4): MetaSequential(\n",
              "        (0): BatchLinear(in_features=256, out_features=1, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (hyper_net): HyperNetwork(\n",
              "    (nets): ModuleList(\n",
              "      (0): FCBlock(\n",
              "        (net): MetaSequential(\n",
              "          (0): MetaSequential(\n",
              "            (0): BatchLinear(in_features=784, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=512, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): FCBlock(\n",
              "        (net): MetaSequential(\n",
              "          (0): MetaSequential(\n",
              "            (0): BatchLinear(in_features=784, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): FCBlock(\n",
              "        (net): MetaSequential(\n",
              "          (0): MetaSequential(\n",
              "            (0): BatchLinear(in_features=784, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=65536, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): FCBlock(\n",
              "        (net): MetaSequential(\n",
              "          (0): MetaSequential(\n",
              "            (0): BatchLinear(in_features=784, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): FCBlock(\n",
              "        (net): MetaSequential(\n",
              "          (0): MetaSequential(\n",
              "            (0): BatchLinear(in_features=784, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=65536, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): FCBlock(\n",
              "        (net): MetaSequential(\n",
              "          (0): MetaSequential(\n",
              "            (0): BatchLinear(in_features=784, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (6): FCBlock(\n",
              "        (net): MetaSequential(\n",
              "          (0): MetaSequential(\n",
              "            (0): BatchLinear(in_features=784, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=65536, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): FCBlock(\n",
              "        (net): MetaSequential(\n",
              "          (0): MetaSequential(\n",
              "            (0): BatchLinear(in_features=784, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (8): FCBlock(\n",
              "        (net): MetaSequential(\n",
              "          (0): MetaSequential(\n",
              "            (0): BatchLinear(in_features=784, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): FCBlock(\n",
              "        (net): MetaSequential(\n",
              "          (0): MetaSequential(\n",
              "            (0): BatchLinear(in_features=784, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=1, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAPuXmUepoD7"
      },
      "source": [
        "class MNISTSirenDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, trainMNIST):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.trainMNIST = trainMNIST\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.trainMNIST)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = torch.Tensor(np.array(self.trainMNIST[idx][0])).reshape((784, 1))\n",
        "        coord = get_mgrid(28, 2)\n",
        "\n",
        "        return image, coord"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6DRBrITqWfd"
      },
      "source": [
        "loader = DataLoader(MNISTSirenDataset(mnist_trainset), batch_size=32, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "WC0L004vBusR",
        "outputId": "d1834dec-3384-42cb-edd3-45d06dfb4bf3"
      },
      "source": [
        "total_steps = 1000000 # Since the whole image is our dataset, this just means 500 gradient descent steps.\n",
        "steps_til_summary = 50\n",
        "batch_size = 8\n",
        "\n",
        "optim = torch.optim.Adam(lr=5e-5, params=[\n",
        "                            {'params': net.hyper_net.parameters()},\n",
        "                            # {'params': net.encoder.parameters()}\n",
        "                        ])\n",
        "\n",
        "for e in range(100):\n",
        "  for i, (img, coords) in enumerate(loader):\n",
        "      \n",
        "      # model_input, ground_truth = coords# get_mgrid(28, 2), torch.Tensor(np.array(mnist_trainset[step % len(mnist_trainset)][0])).reshape((784, 1))\n",
        "      # model_input, ground_truth = model_input.cuda(), ground_truth.cuda()\n",
        "      img, coords = img.cuda(), coords.cuda()\n",
        "\n",
        "      out = net_2({'embedding': img.view((32, 784)).cuda() / 255, 'coords': model_input.cuda()})\n",
        "\n",
        "      model_output = out[\"model_out\"]\n",
        "      embedding = out[\"latent_vec\"]\n",
        "      hypo_params = out[\"hypo_params\"]\n",
        "\n",
        "      all_hypo_params = torch.cat([x.view(-1) for x in list(hypo_params.values())])\n",
        "\n",
        "      loss = ((model_output.cuda() - (img / 255))**2).mean() + 100 * ((all_hypo_params.cuda())**2).mean() #  + 0.1 * ((embedding.cuda())**2).mean()\n",
        "      \n",
        "      if not i % 250:\n",
        "          print(\"Step %d, Total loss %0.6f\" % (i, loss))\n",
        "\n",
        "          print(torch.max(model_output))\n",
        "          print(torch.max(img))\n",
        "\n",
        "          fig, axes = plt.subplots(1,3, figsize=(18,6))\n",
        "          axes[0].imshow((model_output[0]).cpu().view(28,28).detach().numpy())\n",
        "          axes[1].imshow((img / 255)[0].cpu().view(28,28).detach().numpy())\n",
        "          plt.show()\n",
        "\n",
        "      optim.zero_grad()\n",
        "      loss.backward()\n",
        "      optim.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-45e77a0c1c07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'embedding'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coords'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_out\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'net_2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT-ZW-n8060y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2_Doad30cxQ"
      },
      "source": [
        "# torch.save(net_2.state_dict(), \"mnist_siren\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZGgOlLpU6So",
        "outputId": "1f44e636-ba0e-4890-cdc4-30229372c24f"
      },
      "source": [
        "# net_2 = ConvolutionalNeuralProcessImplicit2DHypernet(1, 1, image_resolution=28)\n",
        "# net_2.cuda()\n",
        "# net_2.load_state_dict(torch.load(\"/content/drive/My Drive/mnist_flatten_siren\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bTjczog1cMn"
      },
      "source": [
        "# MNISTSiren + Pre-trained CNN Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJt80_7r1fPX"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmshREaM17Gz",
        "outputId": "91120e46-fb7d-45dd-ba05-71f609183153"
      },
      "source": [
        "n_epochs = 3\n",
        "batch_size_train = 64\n",
        "batch_size_test = 1000\n",
        "learning_rate = 0.01\n",
        "momentum = 0.5\n",
        "log_interval = 10\n",
        "\n",
        "random_seed = 1\n",
        "torch.backends.cudnn.enabled = False\n",
        "torch.manual_seed(random_seed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f94313282d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdkkbzIt2Woc"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])),\n",
        "  batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
        "                             transform=torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               torchvision.transforms.Normalize(\n",
        "                                 (0.1307,), (0.3081,))\n",
        "                             ])),\n",
        "  batch_size=batch_size_test, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWfHgTcj1bNK"
      },
      "source": [
        "class MNISTClassifierNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTClassifierNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM7pkB1Q1yAQ"
      },
      "source": [
        "network = MNISTClassifierNet()\n",
        "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
        "                      momentum=momentum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtMyhPMY2dkY"
      },
      "source": [
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH06KMPM2Hj7"
      },
      "source": [
        "def train(epoch):\n",
        "  network.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    output = network(data)\n",
        "    loss = F.nll_loss(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % log_interval == 0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "        100. * batch_idx / len(train_loader), loss.item()))\n",
        "      train_losses.append(loss.item())\n",
        "      train_counter.append(\n",
        "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_n0vHx42Pnj"
      },
      "source": [
        "def test():\n",
        "  network.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      output = network(data)\n",
        "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  test_losses.append(test_loss)\n",
        "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    test_loss, correct, len(test_loader.dataset),\n",
        "    100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQSIVvM62MgI",
        "outputId": "13322619-131a-4f26-8850-4bf4c27b9734"
      },
      "source": [
        "test()\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg. loss: 2.3316, Accuracy: 1137/10000 (11%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.339086\n",
            "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.305619\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.314029\n",
            "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.260222\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.289430\n",
            "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.236755\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.186437\n",
            "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.169749\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.186659\n",
            "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.034549\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.098917\n",
            "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.021254\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 1.800838\n",
            "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 1.744249\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.674355\n",
            "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.547719\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.243401\n",
            "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 1.333821\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.086432\n",
            "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 1.173155\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.238948\n",
            "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 1.243752\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 1.085347\n",
            "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.783311\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 1.089187\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.158927\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.818847\n",
            "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 1.027466\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.726083\n",
            "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.918140\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.014655\n",
            "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.850271\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.824834\n",
            "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.944801\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 1.024272\n",
            "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.683549\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.904955\n",
            "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.732501\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.651272\n",
            "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 1.043613\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.761861\n",
            "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.665636\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.611925\n",
            "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.470078\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.635987\n",
            "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.388786\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.819558\n",
            "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.900272\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.450155\n",
            "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.626603\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.460524\n",
            "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.662317\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.786966\n",
            "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.468805\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.592431\n",
            "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.642478\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.680420\n",
            "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.718027\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.498802\n",
            "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.531387\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.547799\n",
            "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.948710\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.694005\n",
            "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.484087\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.481445\n",
            "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.574262\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.579353\n",
            "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.525797\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.461939\n",
            "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.507376\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.404071\n",
            "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.642472\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.468348\n",
            "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.661629\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.337835\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.382446\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.469429\n",
            "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.520587\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.328572\n",
            "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.454077\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.731731\n",
            "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.515173\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.337981\n",
            "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.399709\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.623730\n",
            "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.392963\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.618844\n",
            "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.426629\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.253764\n",
            "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.427503\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.387975\n",
            "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.700944\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.601125\n",
            "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.385773\n",
            "\n",
            "Test set: Avg. loss: 0.2000, Accuracy: 9387/10000 (94%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.378516\n",
            "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.662582\n",
            "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.261621\n",
            "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.242998\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.562746\n",
            "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.396597\n",
            "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.442257\n",
            "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.416384\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.340874\n",
            "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.681483\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.275536\n",
            "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.336285\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.504212\n",
            "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.321898\n",
            "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.454758\n",
            "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.479162\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.457430\n",
            "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.404733\n",
            "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.597542\n",
            "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.584752\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.325390\n",
            "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.595432\n",
            "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.388268\n",
            "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.505506\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.454060\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.288710\n",
            "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.265995\n",
            "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.549229\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.430167\n",
            "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.311274\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.482034\n",
            "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.289607\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.169274\n",
            "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.319042\n",
            "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.213186\n",
            "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.281353\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.354788\n",
            "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.353090\n",
            "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.326617\n",
            "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.377925\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.469164\n",
            "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.332062\n",
            "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.392581\n",
            "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.396722\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.339486\n",
            "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.531604\n",
            "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.297084\n",
            "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.386200\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.489504\n",
            "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.447713\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.341910\n",
            "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.457871\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.429096\n",
            "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.437317\n",
            "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.260997\n",
            "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.373318\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.491906\n",
            "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.331638\n",
            "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.350353\n",
            "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.428295\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.442433\n",
            "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.473638\n",
            "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.294221\n",
            "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.290650\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.443004\n",
            "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.412427\n",
            "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.230627\n",
            "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.345937\n",
            "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.330329\n",
            "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.363810\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.258715\n",
            "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.315634\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.360158\n",
            "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.240880\n",
            "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.231139\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.218255\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.237971\n",
            "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.296271\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.354486\n",
            "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.500559\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.324899\n",
            "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.400899\n",
            "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.380055\n",
            "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.500972\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.352135\n",
            "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.387492\n",
            "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.161797\n",
            "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.515358\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.255966\n",
            "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.435475\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.202952\n",
            "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.509660\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.435445\n",
            "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.177694\n",
            "\n",
            "Test set: Avg. loss: 0.1233, Accuracy: 9632/10000 (96%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.530613\n",
            "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.334036\n",
            "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.208690\n",
            "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.265025\n",
            "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.143357\n",
            "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.302640\n",
            "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.269140\n",
            "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.230710\n",
            "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.236523\n",
            "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.304357\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.386528\n",
            "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.286007\n",
            "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.172991\n",
            "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.439590\n",
            "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.253588\n",
            "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.332894\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.750671\n",
            "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.291570\n",
            "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.364411\n",
            "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.216417\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.355886\n",
            "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.337395\n",
            "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.359294\n",
            "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.277765\n",
            "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.321227\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.192124\n",
            "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.384490\n",
            "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.278959\n",
            "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.202628\n",
            "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.250527\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.274612\n",
            "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.194432\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.156531\n",
            "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.221782\n",
            "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.268716\n",
            "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.325970\n",
            "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.282262\n",
            "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.200696\n",
            "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.421756\n",
            "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.356756\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.287913\n",
            "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.283318\n",
            "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.253751\n",
            "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.232968\n",
            "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.419961\n",
            "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.187787\n",
            "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.280065\n",
            "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.392482\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.250434\n",
            "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.184288\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.527168\n",
            "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.337109\n",
            "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.444593\n",
            "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.275785\n",
            "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.189527\n",
            "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.381061\n",
            "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.130302\n",
            "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.232422\n",
            "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.282351\n",
            "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.499934\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.176853\n",
            "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.273099\n",
            "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.325111\n",
            "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.194734\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.218418\n",
            "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.355428\n",
            "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.239524\n",
            "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.346278\n",
            "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.142962\n",
            "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.262739\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.181682\n",
            "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.296050\n",
            "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.332553\n",
            "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.146961\n",
            "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.399680\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.177904\n",
            "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.181859\n",
            "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.350620\n",
            "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.221839\n",
            "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.313512\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.185052\n",
            "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.375563\n",
            "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.160117\n",
            "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.301241\n",
            "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.329843\n",
            "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.327801\n",
            "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.224432\n",
            "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.219883\n",
            "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.410052\n",
            "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.261317\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.244896\n",
            "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.293178\n",
            "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.491637\n",
            "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.261960\n",
            "\n",
            "Test set: Avg. loss: 0.1010, Accuracy: 9674/10000 (97%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M8v6yqv27CV"
      },
      "source": [
        "network = network.cuda()\n",
        "def network_head(x):\n",
        "  x = F.relu(F.max_pool2d(network.conv1(x), 2))\n",
        "  x = F.relu(F.max_pool2d(network.conv2_drop(network.conv2(x)), 2))\n",
        "  x = x.view(-1, 320)\n",
        "  x = F.relu(network.fc1(x))\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oHt6PjK5nYM",
        "outputId": "485f31df-c9f3-4550-ad7d-a381ca2a0ba5"
      },
      "source": [
        "net_3 = ConvolutionalNeuralProcessImplicit2DHypernet(1, 1, image_resolution=28, latent_dim=50)\n",
        "net_3.cuda()\n",
        "# net_3.load_state_dict(torch.load(\"/content/drive/My Drive/mnist_flatten_siren\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvolutionalNeuralProcessImplicit2DHypernet(\n",
              "  (encoder): ConvImgEncoder(\n",
              "    (conv_theta): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (cnn): Sequential(\n",
              "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2dResBlock(\n",
              "        (convs): Sequential(\n",
              "          (0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          (1): ReLU()\n",
              "          (2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          (3): ReLU()\n",
              "        )\n",
              "        (final_relu): ReLU()\n",
              "      )\n",
              "      (3): Conv2dResBlock(\n",
              "        (convs): Sequential(\n",
              "          (0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          (1): ReLU()\n",
              "          (2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          (3): ReLU()\n",
              "        )\n",
              "        (final_relu): ReLU()\n",
              "      )\n",
              "      (4): Conv2dResBlock(\n",
              "        (convs): Sequential(\n",
              "          (0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          (1): ReLU()\n",
              "          (2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          (3): ReLU()\n",
              "        )\n",
              "        (final_relu): ReLU()\n",
              "      )\n",
              "      (5): Conv2dResBlock(\n",
              "        (convs): Sequential(\n",
              "          (0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          (1): ReLU()\n",
              "          (2): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          (3): ReLU()\n",
              "        )\n",
              "        (final_relu): ReLU()\n",
              "      )\n",
              "      (6): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (relu_2): ReLU(inplace=True)\n",
              "    (fc): Linear(in_features=784, out_features=1, bias=True)\n",
              "  )\n",
              "  (hypo_net): FCBlock(\n",
              "    (net): MetaSequential(\n",
              "      (0): MetaSequential(\n",
              "        (0): BatchLinear(in_features=2, out_features=256, bias=True)\n",
              "        (1): Sine()\n",
              "      )\n",
              "      (1): MetaSequential(\n",
              "        (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "        (1): Sine()\n",
              "      )\n",
              "      (2): MetaSequential(\n",
              "        (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "        (1): Sine()\n",
              "      )\n",
              "      (3): MetaSequential(\n",
              "        (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "        (1): Sine()\n",
              "      )\n",
              "      (4): MetaSequential(\n",
              "        (0): BatchLinear(in_features=256, out_features=1, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (hyper_net): HyperNetwork(\n",
              "    (nets): ModuleList(\n",
              "      (0): FCBlock(\n",
              "        (net): MetaSequential(\n",
              "          (0): MetaSequential(\n",
              "            (0): BatchLinear(in_features=50, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=512, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): FCBlock(\n",
              "        (net): MetaSequential(\n",
              "          (0): MetaSequential(\n",
              "            (0): BatchLinear(in_features=50, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): FCBlock(\n",
              "        (net): MetaSequential(\n",
              "          (0): MetaSequential(\n",
              "            (0): BatchLinear(in_features=50, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=65536, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): FCBlock(\n",
              "        (net): MetaSequential(\n",
              "          (0): MetaSequential(\n",
              "            (0): BatchLinear(in_features=50, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): FCBlock(\n",
              "        (net): MetaSequential(\n",
              "          (0): MetaSequential(\n",
              "            (0): BatchLinear(in_features=50, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=65536, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): FCBlock(\n",
              "        (net): MetaSequential(\n",
              "          (0): MetaSequential(\n",
              "            (0): BatchLinear(in_features=50, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (6): FCBlock(\n",
              "        (net): MetaSequential(\n",
              "          (0): MetaSequential(\n",
              "            (0): BatchLinear(in_features=50, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=65536, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): FCBlock(\n",
              "        (net): MetaSequential(\n",
              "          (0): MetaSequential(\n",
              "            (0): BatchLinear(in_features=50, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (8): FCBlock(\n",
              "        (net): MetaSequential(\n",
              "          (0): MetaSequential(\n",
              "            (0): BatchLinear(in_features=50, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): FCBlock(\n",
              "        (net): MetaSequential(\n",
              "          (0): MetaSequential(\n",
              "            (0): BatchLinear(in_features=50, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (1): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=256, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "          )\n",
              "          (2): MetaSequential(\n",
              "            (0): BatchLinear(in_features=256, out_features=1, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dSmJOUcwV2Ea",
        "outputId": "2826e444-096b-4faa-a9b1-80806e5eaf9a"
      },
      "source": [
        "total_steps = 1000000 # Since the whole image is our dataset, this just means 500 gradient descent steps.\n",
        "steps_til_summary = 50\n",
        "batch_size = 8\n",
        "\n",
        "optim = torch.optim.Adam(lr=5e-5, params=[\n",
        "                            {'params': net_3.hyper_net.parameters()},\n",
        "                            # {'params': net.encoder.parameters()}\n",
        "                        ])\n",
        "\n",
        "for e in range(100):\n",
        "  for i, (img, coords) in enumerate(loader):\n",
        "      \n",
        "      # model_input, ground_truth = coords# get_mgrid(28, 2), torch.Tensor(np.array(mnist_trainset[step % len(mnist_trainset)][0])).reshape((784, 1))\n",
        "      # model_input, ground_truth = model_input.cuda(), ground_truth.cuda()\n",
        "      img, coords = img.cuda(), coords.cuda()\n",
        "      \n",
        "      with torch.no_grad():\n",
        "        embedding = network_head(img.reshape(-1, 1, 28, 28)).cuda() / 1000\n",
        "\n",
        "      out = net_3({'embedding': embedding, 'coords': coords.cuda()})\n",
        "\n",
        "      model_output = out[\"model_out\"]\n",
        "      embedding = out[\"latent_vec\"]\n",
        "      hypo_params = out[\"hypo_params\"]\n",
        "\n",
        "      all_hypo_params = torch.cat([x.view(-1) for x in list(hypo_params.values())])\n",
        "\n",
        "      loss = ((model_output.cuda() - (img / 255))**2).mean() + 100 * ((all_hypo_params.cuda())**2).mean() #  + 0.1 * ((embedding.cuda())**2).mean()\n",
        "      \n",
        "      if not i % 250:\n",
        "          print(\"Step %d, Total loss %0.6f\" % (i, loss))\n",
        "\n",
        "          print(torch.max(model_output))\n",
        "          print(torch.max(img))\n",
        "\n",
        "          fig, axes = plt.subplots(1,3, figsize=(18,6))\n",
        "          axes[0].imshow((model_output[0]).cpu().view(28,28).detach().numpy())\n",
        "          axes[1].imshow((img / 255)[0].cpu().view(28,28).detach().numpy())\n",
        "          plt.show()\n",
        "\n",
        "      optim.zero_grad()\n",
        "      loss.backward()\n",
        "      optim.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLgkZBz-7QiA"
      },
      "source": [
        "torch.save(net_3.state_dict(), \"mnist_siren_CNN\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ_Pg7cMYfgz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}